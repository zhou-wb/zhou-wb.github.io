---
layout: custom
---




<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>events</title>
<link href="https://fonts.googleapis.com/css2?family=Poppins:wght@400;600;700;900&display=swap" rel="stylesheet">
<script src="https://cdn.tailwindcss.com"></script>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/all.min.css">
<style>
  .h1_1 {
    font-size: 40px!important; 
    font-weight: 900!important;
  }

  .h2_1 {
    color: #007BFF !important;
    font-size: 51px!important; 
    font-weight: 500 !important;
    margin-top: -2.5rem !important;
    margin-bottom: 4rem !important
  }

  .textarea {
    color: #FFF !important;
    font-weight: 600 !important;
    font-size: larger !important;
  }
  .textareahead {
      color: #FFF !important;
      font-size: larger !important;
      font-size: 30px!important;
      font-weight: 700!important;
    }
  /* .conference-background {
    background-image: url('/assets/img/conferencebg.jpg');
    background-size: cover ; 
    background-position: center; 
    width: 100%; 
    padding-top: 5rem !important;
    padding-bottom: 5rem !important;
  } */
  /* .conference-background {
  background-image: url(/assets/img/bg_2.jpg);
    background-size: cover;
    background-position: center;
    margin-left: -15% !important;
    width: 130%;
    padding-top: 5rem!important;
    padding-bottom: 5rem!important;
    padding-left: 20% !important;
  } */

  .conference-background {
  display: flex;
  flex-direction: column;
  justify-content: center; 
  align-items: start; 
  background-image: url('/assets/img/bg_3.jpg');
  background-size: cover;
  /* background-position: center; */
  /* margin-left: -15% !important; */
  /* width: 130%; */
  background-attachment: fixed !important; 
  /* background-repeat: no-repeat; */
  background-position: center center;      
  padding-top: 5rem !important;
  padding-bottom: 5rem !important;
  /* padding-left: 20% !important; */
  height: 17rem; 
  /* width: 122%;
  margin-left: -11%; */
  position: relative;
  margin-top: 1.5rem;
  /* left: 50%;
  transform: translateX(-50%); */
  width: 100vw; 
  margin-left: -50vw; 
  left: 50%;
}

.text-container {
  position: absolute;
  top: 50%;
  left: calc(50% - min(40%,39rem));
  transform: translateY(-50%);
  width: auto;
}
  .header-container {
  display: flex;
  align-items: stretch; 
  flex-wrap: wrap;
}

.title-container {
  display: flex;
  flex-direction: column;
  justify-content: center; 
  margin-bottom: -40px;
  max-width: 917px !important;
}
.image-container {
  position: relative;
  overflow: hidden;
  margin-left: auto;
  order: 2;
  align-items: center;
  display: flex;
  padding-top: 39px;
}
.conference-image {
  max-width: 100%;
  max-height: 100px;
  object-fit: cover;
  /* opacity: 0.2; */
}

@media (max-width: 1536px) {
  .image-container {
    margin-left: -5px;
    order: 1;
    margin-bottom: -2rem;
    margin-top: -2rem;
  }

  .title-container {
    order: 2; 
    width: 100%; 
  }
  .conference-image {
  max-width: 400px;
  max-height: 120px;
  object-fit: cover;
}
}
/* .conference-image {
  position: absolute;
  top: 50%;
  left: 50%;
  transform: translate(-50%, -50%);
  max-width: 100%;
  height: auto;
} */

  body {
    font-family: 'Poppins', sans-serif !important;  
  }

  .schedule {
  width: 100%; 
  margin: 0; 
  background: rgba(0,123,255, 0.04);
  border-radius: 0;
  overflow: hidden;
  box-shadow: rgba(0,123,255, 0.4) 5px 5px, rgba(0,123,255, 0.3) 10px 10px, rgba(0,123,255, 0.2) 15px 15px, rgba(0,123,255, 0.1) 20px 20px, rgba(0,123,255, 0.05) 25px 25px;
  margin-bottom: 4rem;
  padding: 1rem;
}

.session {
  display: flex;
  align-items: center;
  border-bottom: 0px solid #eee;
  padding-left: 1rem;
  padding-top: 10px;
  padding-bottom: 10px;
}

.time {
  display: flex;
  justify-content: center; 
  align-items: center; 
  flex: 0 0 20%; 
  font-weight: 600;
  color: #007BFF;
  margin-right: 1rem;
}

.details {
  flex: 1;
}

  .title {
    font-size: 18px;
    margin-bottom: 5px;
    font-weight: 600;
  }
  .speaker {
    font-size: 16px;
    color: #666;
  }
  .speaker-container {
  /* margin: 20px auto; */
  display: flex;
  flex-wrap: wrap; 
  /* gap: 20px;  */
}

.speaker-profile {
  /* display: flex; */
  align-items: flex-start;
  /* flex-wrap: wrap; */
  gap: 1rem;
  margin-bottom: 2rem;
}

.speaker-photo {
  width: 12rem;
  object-fit: cover;
  min-height: 10rem;
  max-height: 13rem;
  margin-right: 2rem;
  margin-top: 7px;
  margin-bottom: 1rem;
  float: left;
}

.speaker-content {
  flex: 1;
}

.speaker-name {
  font-weight: bold;
  font-size: larger;

}

.speaker-title {
  /* font-weight: bold; */
  font-size: 16px;
  color: #666; 
}
.speaker-link a {
    color: #007BFF;
    text-decoration: none;
  }

.speaker-abstract {
  font-style: normal;
}

.speaker-bio {
  font-weight: normal;
}

.conference-materials {
  margin: 2rem auto;
}

.material-detail {
  background-color: rgba(0,123,255,0.04);
  margin-bottom: 1rem;
  /* border: 1px solid var(--global-distill-app-color); */
  /* box-shadow: 0 2px 4px var(--global-divider-color); */
  /* box-shadow: 0 2px 4px rgba(0,123,255,0.3); */
  transition: all 0.3s ease-in-out;
}

.material-summary {
  font-weight: 600;
  color: #007BFF;
  padding: 1rem;
  margin: 0;
  cursor: pointer;
  outline: none;
  position: relative;
  list-style: none;
  transition: all 0.3s ease-in-out;
}

.material-summary::after {
  content: '▼';
  position: absolute;
  right: 1rem;
  transition: transform 0.3s ease-in-out;
}

.material-detail[open] .material-summary::after {
  transform: rotate(180deg);
}

.material-content {
  padding: 1rem;
  line-height: 1.6;
  max-height: 0;
  overflow: overlay;
  transition: max-height 0.3s ease-in-out;
}

.material-content b {
  font-weight: 600;
}s

.material-content ol {
  padding-left: 10px; 
  list-style-type: none; 
  margin-top: 1rem;
}
.material-content a{
  color: #007BFF;
  text-decoration: none;
}

.material-content ol li {
  position: relative; 
  padding-left: 20px; 
  margin-bottom: 10px; 
  margin-top: 1rem;
}

.material-content ol li::before {
  content: "•"; 
  color: #007BFF; 
  font-weight: bold; 
  position: absolute; 
  left: 0; 
  top: 0; 
  font-size: 20px;
}

.material-content-name{
  font-weight:600;
  font-size:initial; 
  margin-top:-1rem; 
  margin-bottom:1rem;
}
.material-detail[open] .material-content {
  max-height: 30rem; 
}

.material-summary:hover {
  background-color: var(--global-hover-colorr);
}

details > summary {
  list-style: none;
}
details > summary::-webkit-details-marker {
  display: none;
}

.logos-container {
  display: flex;
  justify-content: center; 
  align-items: center;
  gap: 20px; 
  /* padding: 20px 0;  */
  margin-top: 1rem;
  flex-wrap:wrap
}

.logos-container img {
  max-height: min(7rem,18vw);
  width: auto; 
  transition: transform 0.3s ease;
}

.logos-container img:hover {
  transform: scale(1.1); 
}

.foot-title {
  /* font-weight: bold; */
  font-size: 24px;
  color: #666; 
  font-weight: 700
}
.foot-link a {
    color: #007BFF;
    text-decoration: none;
    font-size: 24px;
    font-weight: 300
  }

.foot-title b {
  font-size: 32px;
  font-weight: 700;
  }
  
  .register-button {
    display: inline-block;
    /* background-color: rgba(0, 123, 255, 0.7);  */
    color: white !important; 
    padding: 10px 20px; 
    text-align: center; 
    text-decoration: none !important; 
    font-size: 21px; 
    /* border-radius: 0;  */
    transition: all 0.3s ease; 
    position: relative; 
    overflow: hidden; 
    margin-bottom: 1rem;

    border-radius: 5px;
    background: rgba(0, 123, 255, 0.6);
    /* box-shadow:  5px 5px 10px #bebebe,
                -5px -5px 10px #ffffff; */
}

.register-button::after {
    content: '→';
    position: absolute;
    right: -20px; 
    top: 50%; 
    transform: translateY(-50%); 
    transition: right 0.3s ease; 
}

.register-button:hover::after {
    right: 10px; 
}


.register-button:hover {
  padding-right: 40px;
    box-shadow: 
        rgba(0,123,255, 0.4) 5px 5px, 
        rgba(0,123,255, 0.3) 10px 10px, 
        rgba(0,123,255, 0.2) 15px 15px, 
        rgba(0,123,255, 0.1) 20px 20px, 
        rgba(0,123,255, 0.05) 25px 25px; 

  }

</style>
</head>

<body class="bg-white text-gray-800">
<div class="container mx-auto px-4">
  <div class = "header-container">
    <div class="title-container">
      <h1 class="h1_1 text-6xl font-bold mt-10 mb-5 "> Workshop on</h1>
      <h2 class="h2_1 text-5xl font-bold mb-5">Frontiers of Image Science and Visual Computing 2024</h2>
    </div>
    <div class="image-container">
    <img src="/assets/img/logos/Eng_.jpg" alt="HKU" class="conference-image">
    </div>
  </div>
  <!-- <p class="mb-10">WELIGHT workshop presents a annual workshop attended by tens of thousands of industry experts. Considered the world's largest, most influential workshops on computer graphics and interactive techniques, these workshops inspire progress through education and collaboration.</p> -->

  <div class="bg-gray-200 p-5 mb-5 conference-background">
    <div class="text-container">
      <h3 class="text-3xl font-bold mb-2 textareahead">Let there be light</h3>
      <p class="mb-2 textarea">8 April, 2024 PM</p>
      <p class="mb-2 textarea">Rayson Huang Lecture Theatre, The University of Hong Kong, HONG KONG SAR</p>
    </div>
  </div>


  <h2 class="text-4xl font-bold mb-5">Workshop Objectives</h2>
  <div class="grid grid-cols-1 md:grid-cols-2  mb-10">
    <!-- Column 1 -->
    <div>
      <div class="flex items-start mb-2" style = "margin-bottom: 2rem !important">
        <div class="text-red-500 mr-2">  
          <i class="fas fa-circle"></i>
        </div>
        <div>
          <h4 class="font-bold" >Encourage Innovative Spirit</h4>
          <!-- <p>SIGGRAPH workshops must recognize, encourage and support the effective participation of their constituents.</p> -->
        </div>
      </div>

      <div class="flex items-start mb-2" style = "margin-bottom: 2rem !important">
        <div class="text-red-500 mr-2">
          <i class="fas fa-circle"></i>
        </div>
        <div>
          <h4 class="font-bold " >Promote Excellence and Sustain Quality</h4>
          <!-- <p>attract and deliver high-quality results, prioritizing integrity, content, presentation and experience.</p> -->
        </div>
      </div>
    </div>

    <!-- Column 2 -->
    <div>
      <div class="flex items-start mb-2" style = "margin-bottom: 2rem !important">
        <div class="text-red-500 mr-2">
          <i class="fas fa-circle"></i>
        </div>
        <div>
          <h4 class="font-bold " >Strive for Improvement</h4>
          <!-- <p>Continuously review processes and results to support community satisfaction, using past experiences as opportunities for improvement.</p> -->
        </div>
      </div>

      <div class="flex items-start" style = "margin-bottom: 2rem !important" >
        <div class="text-red-500 mr-2">
          <i class="fas fa-circle"></i>
        </div>
        <div>
          <h4 class="font-bold " >Connect Communities</h4>
          <!-- <p>Break down silos between disciplines and encourage collaboration to advance the theory and practice of computer graphics and interactive techniques.</p> -->
        </div>
      </div>

    </div>
  </div>

 
  <h2 class="text-4xl font-bold mb-5" style = "margin-top: -2rem !important">Schedule</h2>
  <a href="https://hkuems1.hku.hk/hkuems/ec_hdetail.aspx?guest=Y&ueid=93119" target="_blank" class="register-button">Register Now (Free)</a>

  <!-- <span class="foot-link" ><a href="https://www.eee.hku.hk/">Register Now (Free)</a></span> -->

  <div class="schedule">
    <div class="session">
      <div class="time">14:15 - 14:30</div>
      <div class="details">
        <div class="title">Check-in & Welcome Preview</div>
        <!-- <div class="speaker">Evan Peng</div> -->
      </div>
    </div>

    <div class="session">
      <div class="time">14:30 - 14:40</div>
      <div class="details">
        <div class="title">Opening Remarks</div>
        <div class="speaker">David Srolovitz, Dean of Engineering, The University of Hong Kong (HKU)</div>
      </div>
    </div>

    <div class="session">
      <div class="time">14:40 - 15:30</div>
      <div class="details">
        <div class="title">William Mong Distinguished Lecture: Simulation Technologies for Image Systems</div>
        <div class="speaker">Brian A. Wandell, Stanford University</div>
      </div>
    </div>

    
    <div class="session">
      <div class="time">15:30 - 15:35</div>
      <div class="details">
        <div class="title">Pitching for Stanford Center for Image Systems Engineering (SCIEN)</div>
        <div class="speaker">Joyce Farrell, Executive Director of SCIEN</div>
      </div>
    </div>

    <div class="session">
      <div class="time">15:35 - 15:45</div>
      <div class="details">
        <div class="title">Pitching for Imaging Research at HKU Engineering</div>
        <div class="speaker">TBD</div>
      </div>
    </div>

    <div class="session">
      <div class="time">15:45 - 16:15</div>
      <div class="details">
        <div class="title">Tea Reception</div>
        <!-- <div class="speaker">David Srolovitz, Dean of Engineering</div> -->
      </div>
    </div>


    <div class="session">
      <div class="time">16:15 - 16:40</div>
      <div class="details">
        <div class="title">Self-Calibrating, Fully Differentiable NLOS Inverse Rendering</div>
        <div class="speaker">Min H. Kim, Korea Advanced Institute of Science and Technology (KAIST)</div>
      </div>
    </div>

    <div class="session">
      <div class="time">16:40 - 17:05</div>
      <div class="details">
        <div class="title">High-speed Photometric Analysis using an Event Camera</div>
        <div class="speaker">Boxin Shi, Peking University (PKU)</div>
      </div>
    </div>

    <div class="session">
      <div class="time">17:05 - 17:25</div>
      <div class="details">
        <div class="title">TBD</div>
        <div class="speaker">Kede Ma, CityU of Hong Kong</div>
      </div>
    </div>

    <div class="session">
      <div class="time">17:25 - 17:45</div>
      <div class="details">
        <div class="title">TBD</div>
        <div class="speaker">TBD, Chinese University of Hong Kong</div>
      </div>
    </div>

    <div class="session">
      <div class="time">17:45 - 17:50</div>
      <div class="details">
        <div class="title">Closing Remarks</div>
        <div class="speaker">Head of Department, HKU & Evan Y. Peng</div>
      </div>
    </div>


  </div>
    
  <!-- <h2 class="text-4xl font-bold mb-5">Conference Materials</h2> -->

  
  
  

  <h2 class="text-4xl font-bold mb-5">Speakers</h2>

    <div class="speaker-container">

      <div class="speaker-profile">
        <img class="speaker-photo" src="/assets/img/workshop/Brian A. Wandell.jpg" alt="Speaker Name">
        <div class="speaker-content">
          <h2 class="speaker-name">Brian A. Wandell</h2>
          <h3 class="speaker-title">Founding Director, Stanford’s Center for Neurobiological Imaging, Stanford University</h3>
          <p class="speaker-link"><a href="https://wandell.vista.su.domains/blog/" target="_blank">Personal Website</a></p>
          <p class="speaker-abstract">Brian A. Wandell, the Isaac and Madeline Stein Family Professor, joined the Stanford Psychology faculty in 1979. He is a member, 
            by courtesy, of Electrical Engineering, Ophthalmology, and the Graduate School of Education. Wandell is the Founding Director of Stanford’s Center for Cognitive and Neurobiological Imaging, 
            and he served as a Deputy Director of the Wu Tsai Neuroscience Institute  from 2013-2021.  
            His research centers on vision science, spanning visual neuroscience to digital imaging systems (cameras, displays). 
            He was elected to the American Academy of Arts and Sciences in 2011, received the highest honor of the Society for Imaging Science and Technology in 2014, was awarded the George A. 
            Miller prize of the Cognitive Neuroscience Society in 2016, and  Proctor Medal  from the Association for Research in Vision and Ophthalmology in 2021. 
            Wandell was elected to the US National Academy of Sciences in 2003.</p>
        </div>
      </div>

      <div class="speaker-profile">
        <img class="speaker-photo" src="/assets/img/workshop/JoyceFarrell.jpg" alt="Speaker Name">
        <div class="speaker-content">
          <h2 class="speaker-name">Joyce Farrell</h2>
          <h3 class="speaker-title">Executive Director, Stanford Center for Image Systems Engineering</h3>
          <p class="speaker-link"><a href="https://web.stanford.edu/group/scien/cgi-bin/farrell/" target="_blank">Personal Website</a></p>
          <p class="speaker-abstract">Joyce Farrell is the Executive Director of the Stanford Center for Image Systems Engineering. 
            She has more than 20 years of research and professional experience  working at a variety of companies and institutions, 
            including the NASA Ames Research Center, New York University, the Xerox Palo Alto Research Center, 
            Hewlett Packard Laboratories and Shutterfly (a startup company specializing in online digital photo-finishing). 
            She is also the CEO and founder of ImagEval Consulting, LLC.</p>
        </div>
      </div>

      <div class="speaker-profile">
        <img class="speaker-photo" src="/assets/img/workshop/minhkim.jpg" alt="Speaker Name">
        <div class="speaker-content">
          <h2 class="speaker-name">Min H. Kim</h2>
          <h3 class="speaker-title">Chair Professor, KAIST</h3>
          <p class="speaker-link"><a href="https://vclab.kaist.ac.kr/minhkim/" target="_blank">Personal Website</a></p>
          <p class="speaker-abstract">Min H. Kim is a Professor of Computer Science at the KAIST School of Computing, 
            where he directs the Visual Computing Lab (VCLAB). Prior to joining KAIST, he was a postdoctoral researcher at Yale University. 
            He holds a Ph.D. in Computer Science from University College London (UCL). 
            He has received numerous awards, including the SIGGRAPH Technical Paper Award Honorable Mention in 2022. His main research areas are computational imaging, 
            computational photography, 3D imaging, BRDF acquisition, and 3D reconstruction. He has served as Technical Paper Chair for Eurographics 2022, 
            Course Chair for SIGGRAPH Asia 2022, and on many computer graphics and computer vision program committees, including SIGGRAPH, CVPR, ICCV, 
            and Eurographics. He has served as an Associate Editor for top CS journals, including ACM Transactions on Graphics (TOG) and IEEE Transactions on 
            Visualization and Computer Graphics (TVCG).  </p>
        </div>
      </div>


      <div class="speaker-profile">
        <img class="speaker-photo" src="/assets/img/workshop/BoxinShi.png" alt="Speaker Name">
        <div class="speaker-content">
          <h2 class="speaker-name">Boxin Shi</h2>
          <h3 class="speaker-title">Associate Professor, Peking University</h3>
          <p class="speaker-link"><a href="https://camera.pku.edu.cn/index.htm" target="_blank">Personal Website</a></p>
          <p class="speaker-abstract">Boxin Shi is currently a Boya Young Fellow Associate Professor (with tenure) and Research Professor at Peking University, 
            where he leads the Camera Intelligence Lab. He has also been a Young Scientist at Beijing Academy of Artificial Intelligence. 
            He received the PhD degree from the University of Tokyo in 2013. From 2013 to 2017, he did research at MIT Media Lab, 
            Singapore University of Technology and Design, Nanyang Technological University, 
            and National Institute of Advanced Industrial Science and Technology. 
            His research interests are computational photography and computer vision. 
            He received the Okawa Foundation Research Grant in 2021. He has served as an associate editor of TAPMI/IJCV and an area chair of CVPR/ICCV/ECCV. 
            He is a Senior Member of the IEEE/CCF/CSIG, and a Distinguished Lecturer of APSIPA.
          </p>
        </div>
      </div>

      <div class="speaker-profile">
        <img class="speaker-photo" src="/assets/img/workshop/KedeMa.jpeg" alt="Speaker Name">
        <div class="speaker-content">
          <h2 class="speaker-name">Kede Ma</h2>
          <h3 class="speaker-title">Assistant Professor, CityU of Hong Kong</h3>
          <p class="speaker-link"><a href="https://kedema.org/" target="_blank">Personal Website</a></p>
          <p class="speaker-abstract">Kede Ma is an Assistant Professor with the Department of Computer Science at City University of Hong Kong (CityU). 
            He received the B.E. degree from the University of Science and Technology of China (USTC) in 2012, the MASc. and Ph.D. degrees from the University of Waterloo, 
            in 2014 and 2017, respectively. Prior to joining CityU, he was a Research Associate with Howard Hughes Medical Institute and New York University, from 2018 to 2019. </p>
        </div>
      </div>

      <div class="speaker-profile">
        <img class="speaker-photo" src="/assets/img/workshop/TBD.png" alt="Speaker Name">
        <div class="speaker-content">
          <h2 class="speaker-name">TBD</h2>
          <h3 class="speaker-title">Chinese University of Hong Kong</h3>
          <p class="speaker-link"><a href="https://kedema.org/" target="_blank">Personal Website</a></p>
          <p class="speaker-abstract">TBD&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
            &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
            &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
            &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
            &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
          </p>
        </div>
      </div>


      <!-- <div class="speaker-profile">
        <img class="speaker-photo" src="/assets/img/EvanPeng.jpg" alt="Speaker Name">
        <div class="speaker-content">
          <h2 class="speaker-name">Evan Y. Peng</h2>
          <h3 class="speaker-title">PI of WeLight Lab, The University of Hong Kong</h3>
          <p class="speaker-link"><a href="https://www.eee.hku.hk/~evanpeng/" target="_blank">Personal Website</a></p>
          <p class="speaker-abstract">Dr. Evan Y. Peng is currently an Assistant Professor at the University of Hong Kong. Before joining HKU, 
            Dr. Peng was a Postdoctoral Research Scholar at Stanford University. He received his PhD in Computer Science from the Imager Lab, 
            the University of British Columbia, both his MSc and BS in Optical Science and Engineering from State Key Lab of Modern Optical Instrumentation, 
            Zhejiang University. Dr. Peng has been working on several Neural + X projects for cameras, displays, microscopes, and rendering. 
            His unique and cross-disciplinary approach to research has been well received in multiple professional communities 
            (OPTICA, SIGGRAPH, IEEE, SPIE, and SID). He was awarded the Young Researcher Award in 2022 by Asiagraphics. 
            Dr. Peng is serving several professional roles, for instance, technical committee, reviewer, and session chair, in several academic venues. 
            Dr. Peng is also the co-founder of the emerging Wechat Public Account (Tech Blog) "IntelligentOptics".</p>
        </div>
      </div> -->

    </div>

    <div class="conference-materials">
      <h2 class="text-4xl font-bold mb-5">Workshop Materials</h2>
    
    
      <details class="material-detail">
        <summary class="material-summary">William Mong Distinguished Lecture: Simulation Technologies for Image Systems</summary>
        <div class="material-content">
         
            <h2 class="material-content-name">Brian A. Wandell</h2>
            <p>The number and type of imaging systems has grown enormously over the last several decades; these systems are an essential component in mobile communication, medicine, automotive and drone applications. 
              Imaging systems are also increasingly used with deep learning systems that require large amounts of training data. For these reasons software prototyping has become an essential tool for the design, 
              evaluation and training of modern image systems. I will describe three closely related open-source and freely available image systems toolboxes - ISETCam, ISETBio, and ISET3d - that support design and evaluation of whole image systems. 
              The presentation will include examples of how we model the three-dimensional scene spectral radiance, retinal encoding (physiological optics and cone sampling), and image systems hardware (multi-element lenses, image sensors).  
              I will also provide two examples of how we used end-to-end image system simulation to aid understanding and design.
            </p>
            <br>
            <b>Related publications</b>
            <br>
            <ol>
            <li> <a href="https://arxiv.org/abs/2101.01843">ISETAuto: Detecting vehicles with depth and radiance information (2021)</a> . Zhenyi Liu, Joyece Farrell, Brian Wandell, IEEE Access <a href="https://ieeexplore.ieee.org/document/9369340"> ACCESS.2021.3063692 </a></li>
  
            <li> <a href="http://arxiv.org/abs/1902.04258">A system for generating complex physically accurate sensor images for automotive applications (2019)</a>. Zhenyi Liu, Minghao Shen, Jiaqi Zhang, Shuangting Liu, Henryk Blasinski, Trisha Lian, Brian Wandell. IS&T Electronic Imaging Conference, San Francisco.</li>
  
            <li><a href="https://jov.arvojournals.org/article.aspx?articleid=2753752">Ray tracing 3D spectral scenes through human optics models (2019)</a>. Trish Lian, Kevin McKenzie, David Brainard, Nicolas Cottaris, Brian Wandell. Journal of Vision October 2019, Vol.19, 23. doi:<a href="https://doi.org/10.1167/19.12.23">https://doi.org/10.1167/19.12.23</a></li>
  
            <li><a href="https://jov.arvojournals.org/article.aspx?articleid=2770341">A computational observer model of spatial contrast sensitivity: Effects of photocurrent encoding, fixational eye movements and inference engine (2020)</a>. Nicolas P. Cottaris,  Brian A. Wandell,  Fred Rieke, David H. Brainard Journal of Vision doi:<a href="https://doi.org/10.1167/jov.20.7.17">https://doi.org/10.1167/jov.20.7.17</a></li>
            </ol>
            <p>See the wiki pages of the repositories at: <a href="https://github.com/ISET">https://github.com/ISET</a></p>
          
        </div>
      </details>

      <!-- <details class="material-detail">
        <summary class="material-summary">Pitching for Stanford Center for Image Systems Engineering (SCIEN)</summary>
        <div class="material-content">
          <h2 class="material-content-name">Joyce Farrell</h2>
          <p>
            Pitching for Stanford Center for Image Systems Engineering (SCIEN)
  
          </p>
        </div>
      </details> -->

      <details class="material-detail">
        <summary class="material-summary">Self-Calibrating, Fully Differentiable NLOS Inverse Rendering</summary>
        <div class="material-content">
          <h2 class="material-content-name">Min H. Kim</h2>
          <p>
            Existing time-resolved non-line-of-sight (NLOS) imaging methods reconstruct hidden scenes by inverting the optical paths of indirect illumination 
            measured at visible relay surfaces. These methods are prone to reconstruction artifacts due to inversion ambiguities and capture noise, which are 
            typically mitigated through the manual selection of filtering functions and parameters. This talk introduces a fully-differentiable end-to-end NLOS 
            inverse rendering pipeline that self-calibrates the imaging parameters during the reconstruction of hidden scenes, using as input only the measured 
            illumination while working both in the time and frequency domains. The proposed pipeline extracts a geometric representation of the hidden scene 
            from NLOS volumetric intensities and estimates the time-resolved illumination at the relay wall produced by such geometric information using differentiable 
            transient rendering. It then uses gradient descent to optimize imaging parameters by minimizing the error between our simulated time-resolved illumination 
            and the measured illumination. This end-to-end differentiable pipeline couples diffraction-based volumetric NLOS reconstruction with path-space light 
            transport and a simple ray marching technique to extract detailed, dense sets of surface points and normals of hidden scenes. This talk demonstrates the 
            robustness of the proposed method to consistently reconstruct geometry and albedo, even under significant noise levels.  
          </p>
        </div>
      </details>

      <details class="material-detail">
        <summary class="material-summary">High-speed Photometric Analysis using an Event Camera</summary>
        <div class="material-content">
          <h2 class="material-content-name">Boxin Shi</h2>
          <p>
            Compared with conventional frame-based cameras, the event camera has unique advantages, 
            especially in their ability to perceive high-speed moving objects and scenes with high dynamic range. 
            Existing research has fully demonstrated the advantages of event cameras in computer vision tasks such as image deblurring, 
            high dynamic range imaging, and high-speed object detection and recognition. 
            However, the photometric image formation model of event cameras has not been fully analyzed. 
            This talk will share a series of research progress on modeling and analyzing the photometric image formation model 
            of an event camera that records and responses to high-speed radiance changes: obtaining high-fidelity scene radiance estimation 
            via analyzing the transient event frequency, constructing real-time photometric stereo with fast-moving light sources to estimate 
            surface normals, and conducting direct-global illumination separation by capturing shadows of a line occlude swiftly sweeping over 
            the scene.
          </p>
        </div>
      </details>

      <details class="material-detail">
        <summary class="material-summary">TBD</summary>
        <div class="material-content">
          <h2 class="material-content-name">Kede Ma</h2>
          <p>
            TBD
  
          </p>
        </div>
      </details>

      <details class="material-detail">
        <summary class="material-summary">TBD</summary>
        <div class="material-content">
          <h2 class="material-content-name">TBD</h2>
          <p>
            TBD
          </p>
        </div>
      </details>

      
    
    </div>

    <footer style="text-align:center; padding:20px;">
      <p class="foot-title">Organizer: <span class="foot-link" ><a href="https://www.eee.hku.hk/">Faculty of Engineering, The University of Hong Kong</a></span></p>
      <p class="foot-title"> <span class="foot-link" ><a href="https://www.eee.hku.hk/">Department of Electrical & Electronic Engineering</a></span></p>
      <p class="foot-title">Coordinator: <span class="foot-link" ><a href="https://www.eee.hku.hk/~evanpeng/">Evan Y. Peng, HKU EEE x CS</a></span></p>
      <br>
      <p class="foot-title "><b>Acknowledgement: </b></p>

    <div class="logos-container">
      <a href="https://www.hku.hk" target="_blank">
        <img src="/assets/img/logos/HKU.png" alt="Organization 1 Logo">
      </a>
      <a href="https://www.stanford.edu/" target="_blank">
        <img src="/assets/img/logos/stanford.png" alt="Organization 2 Logo">
      </a>
      <a href="https://www.kaist.ac.kr/" target="_blank">
        <img src="/assets/img/logos/KAIST.png" alt="Organization 3 Logo">
      </a>
      <a href="https://www.pku.edu.cn/" target="_blank">
        <img src="/assets/img/logos/PKU.png" alt="Organization 4 Logo">
      </a>
      <a href="https://www.cuhk.edu.hk/" target="_blank">
        <img src="/assets/img/logos/CUHK.png" alt="Organization 5 Logo">
      </a>
      <a href="https://www.cityu.edu.hk/" target="_blank">
        <img src="/assets/img/logos/CityU.png" alt="Organization 6 Logo">
      </a>
    </div>
  </footer>

  </div>





